{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with open('./credentials/openai.txt', 'r') as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from datetime import date\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from langchain.chains import SequentialChain, RouterChain, ConversationChain, LLMRouterChain, MultiPromptChain, TransformChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalData = \"\"\"\\\n",
    "    city: London,\\\n",
    "    job-type: [Data Scientist, AI Software Engineer],\\\n",
    "    monthly-earnings: [1500 usd, 8000 usd],\\\n",
    "    skills: [fast learning, reading complicated documentation,\\ \n",
    "        creating clean data representation, data analysis],\\\n",
    "    interests: [generating ai images, data analysis, large language models],\\\n",
    "    benefits: [flexible hours, remote, health-insurance],\\\n",
    "    technology: [linux -medium, python -advanced, pytorch -advanced, matlabplot -beginner,\\\n",
    "    stable diffusion -beginner, vsc -advanced],\\\n",
    "    languages: [English C1, Polish C1]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobOffer = \"C++ Backend Developer Volue Sp. z o.o. technology image Category: Backend , C++ Mid Must have C++English (B2) Nice to have PythonC#Polish Requirements description C++ programming experience and knowledge of modern C++ Familiarity with Microsoft platform and tools is beneficial Experience working in larger C++ codebases Experience working effectively in a distributed team Some experience with using databases Some knowledge of Python and C# Offer description Volue is a market leader in technologies and services that power the green transition. Around 800 employees work with more than 2 200 customers on energy, power grid, water & infrastructure projects.Our mission is to provide innovative services critical to society, unlocking a cleaner, better and more profitable future. Working towards this goal, Volue has become a leading technology supplier and enabler of the green transition, helping energy companies simplify and optimize everyday operations.We are now looking for Mid/Senior Software Engineer (Mesh Team), who can help us to continuously improve Volue’s ability to provide value to customers in line with the Volue mission. Volue Mesh is a data management system based on object modelling with an integrated time series calculation engine. It is used for more efficient managing of time series data and related information used in different work processes and serves as the core of all future energy production planning and trading solutions.read more Your responsibilities Contribute to all development phases: design, develop, build, deploy and maintain the C++ codebase of Volue Mesh Work closely together with architects, domain experts and backend developers Create and maintain user friendly solutions with clear APIs with efficient resource usage and high performance Work in an international environment, where English is the spoken and written language. The team is distributed in Gdańsk and Trondheim Work in a distributed team with a flexible work-from-home policy Work closely with data intensive applications that are using Mesh and Time Series Management systems to simplify complex workflows show all (7) Job details Online recruitment Recruitment language: Polish&English Start ASAP Permanent contract Remote days: flexible in a week Flexible hours Relocation package: 6000 PLN Perks in the office Free snacks Free coffee Free beverages Gym Canteen Bike parking Playroom Shower No dress code Benefits Sport subscription Life & group insurance Private healthcare English classes Training budget Flat structure Small teams International projects\"\n",
    "jobOffer = \"\"\"\\\n",
    "    city: London,\\\n",
    "    job-type: [Data Scientist, AI Software Engineer],\\\n",
    "    monthly-earnings: [1500 usd, 8000 usd],\\\n",
    "    skills: [fast learning, reading complicated documentation,\\ \n",
    "        creating clean data representation, data analysis],\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryRank = \"\"\"Please, process given job offer and at the beginning the answer put a \\\n",
    "    header: \"<appropriate: match-level>\", where match levels are:\\\n",
    "    [Not appropriate, Acceptable, Ok, Super]. Chosen level shall depend on this how well given job \\\n",
    "    offer matches client job qualifications and preferences.\n",
    "    job offer: \n",
    "    {jobOffer}; \\\n",
    "    client's job qualifications and preferences:\n",
    "    {personalData};\\\n",
    "    \"\"\"\n",
    "\n",
    "promptRank = PromptTemplate(template=queryRank, input_variables=[\"jobOffer\", \"personalData\"])\n",
    "\n",
    "chainRank = LLMChain(llm=llm, prompt=promptRank, output_key='Verdict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"\"\"\n",
    "    You will be given 3 things:\n",
    "    1. Job offer\n",
    "    2. Client's job qualifications and preferences\n",
    "    3. Recruiters' verdict on how well given job offer matches client's job qualifications and preferences, which is one of the following:\n",
    "    [Not appropriate, Acceptable, Ok, Super]\n",
    "\n",
    "    Describe a rationale behind recruiters' verdict. Find argument for why this verdict was given for this candidate and job offer.\n",
    "\n",
    "    Job Offer:\n",
    "    {jobOffer}\n",
    "    Candidate's job qualifications and preferences:\n",
    "    {personalData}\n",
    "    Recruiters' verdict:\n",
    "    {Verdict}\n",
    "    \"\"\"\n",
    "\n",
    "desc_prompt = PromptTemplate(template=desc, input_variables=[\"jobOffer\", \"personalData\", \"Verdict\"])\n",
    "\n",
    "# desc_prompt = PromptTemplate(\n",
    "#     template=desc_template,\n",
    "#     input_variables=[\"Verdict\", \"jobOffer\", \"personalData\"],\n",
    "# )\n",
    "\n",
    "chainDescription = LLMChain(llm=llm, prompt=desc_prompt, output_key='Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chainRank, chainDescription],\n",
    "    input_variables=[\"jobOffer\", \"personalData\"],\n",
    "    output_variables=[\"Verdict\", \"Description\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'jobOffer': '    city: London,    job-type: [Data Scientist, AI Software Engineer],    monthly-earnings: [1500 usd, 8000 usd],    skills: [fast learning, reading complicated documentation,\\\\ \\n        creating clean data representation, data analysis],',\n",
       " 'personalData': '    city: London,    job-type: [Data Scientist, AI Software Engineer],    monthly-earnings: [1500 usd, 8000 usd],    skills: [fast learning, reading complicated documentation,\\\\ \\n        creating clean data representation, data analysis],    interests: [generating ai images, data analysis, large language models],    benefits: [flexible hours, remote, health-insurance],    technology: [linux -medium, python -advanced, pytorch -advanced, matlabplot -beginner,    stable diffusion -beginner, vsc -advanced],    languages: [English C1, Polish C1]\\n    ',\n",
       " 'Verdict': '<Acceptable: match-level>',\n",
       " 'Description': 'The recruiters\\' verdict of \"Acceptable\" for this candidate and job offer indicates that there is a reasonable alignment between the candidate\\'s qualifications and preferences and the requirements of the job offer. \\n\\nHere are the arguments for why this verdict was given:\\n\\n1. City: The candidate and the job offer both specify London as the desired location. This is a positive match as the candidate is interested in working in London.\\n\\n2. Job Type: The candidate\\'s job preferences include both Data Scientist and AI Software Engineer, which align with the job types mentioned in the job offer. This indicates that the candidate is open to either role, increasing the chances of a match.\\n\\n3. Monthly Earnings: The candidate\\'s preferred monthly earnings range (1500 USD - 8000 USD) falls within the range mentioned in the job offer. This suggests that the candidate\\'s salary expectations are in line with what the job offer can provide.\\n\\n4. Skills: The candidate possesses the skills mentioned in the job offer, such as fast learning, reading complicated documentation, creating clean data representation, and data analysis. This indicates that the candidate has the necessary qualifications for the job.\\n\\n5. Interests: The candidate\\'s interests include generating AI images, data analysis, and large language models, which are relevant to the field of Data Science and AI Software Engineering. This suggests that the candidate\\'s interests align with the job offer.\\n\\n6. Benefits: The candidate\\'s preferred benefits include flexible hours, remote work, and health insurance. While the job offer does not explicitly mention these benefits, the fact that the candidate has listed them as preferences indicates that they are open to considering other benefits offered by the employer.\\n\\n7. Technology: The candidate has advanced proficiency in Python and PyTorch, which are mentioned in the job offer. This indicates that the candidate has the necessary technical skills for the job.\\n\\n8. Languages: The candidate is fluent in English and Polish, which are both mentioned in the job offer. This suggests that the candidate meets the language requirements for the job.\\n\\nOverall, the recruiters\\' verdict of \"Acceptable\" is given because there is a reasonable alignment between the candidate\\'s qualifications, preferences, and the requirements of the job offer. While there may be some areas where the candidate\\'s preferences and the job offer do not perfectly match, the overall fit is deemed acceptable for further consideration.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = overall_chain({'jobOffer': jobOffer, 'personalData': personalData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chainRank({\"jobOffer\": jobOffer, \"personalData\": personalData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superVerdictTemplate = \"\"\"You are given a job offer and client personal perferences and qualifications. \\\n",
    "    Your task is to briefly, reason why given job offer would be good choice for a client. Be very enthustiastic, \\\n",
    "    try to limit your answer to just two sentences. Write only that reasoning in your answer. \\\n",
    "    Here is job offer: \n",
    "    {jobOffer} \n",
    "    \n",
    "    And here are informations about a client:\n",
    "    {personalData}\"\"\"\n",
    "    \n",
    "okVerdictTemplate = \"\"\"You are given a job offer and client personal perferences and qualifications. \\\n",
    "    Your task is to briefly, reason why given job offer would be ok choice for a client. \\\n",
    "    Try to limit your answer to just three sentences. Tell what might not suit a client in the offer. \\\n",
    "    Write only that reasoning in your answer. \\\n",
    "    Here is job offer: \n",
    "    {jobOffer} \n",
    "    \n",
    "    And here are informations about a client:\n",
    "    {personalData}\"\"\"\n",
    "    \n",
    "acceptableVerdictTemplate = \"\"\"You are given a job offer and client personal perferences and qualifications. \\\n",
    "    Your task is to briefly, reason why given job offer would be ok choice for a client. \\\n",
    "    Try to limit your answer to just three sentences. Tell that job can be hard to get with the client's qualifications or \\\n",
    "    might just not suit the client's preferences. \\\n",
    "    Write only that reasoning in your answer. \\\n",
    "    Here is job offer: \n",
    "    {jobOffer} \n",
    "    \n",
    "    And here are informations about a client:\n",
    "    {personalData}\"\"\"\n",
    "\n",
    "# def transform_func(inputs: dict) -> dict:\n",
    "#     return {\"description\": \"\"} \n",
    "\n",
    "# default_chainsssss = TransformChain(\n",
    "#     input_variables=[\"input\"],\n",
    "#     output_variables=[\"Reasoning\"],\n",
    "#     transform=transform_func\n",
    "# )\n",
    "\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"Reasoning\")\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"Acceptable\", \n",
    "        \"description\": \"Good for describing acceptable job offers based on 2 variables: job_offer and personal_data\", \n",
    "        \"prompt_template\": acceptableVerdictTemplate\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ok\", \n",
    "        \"description\": \"Good for describing Ok job offers based on 2 variables: job_offer and personal_data\", \n",
    "        \"prompt_template\": okVerdictTemplate\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Super\", \n",
    "        \"description\": \"Good for describing super job offers based on 2 variables: job_offer and personal_data\", \n",
    "        \"prompt_template\": superVerdictTemplate\n",
    "    },\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=['personalData', 'jobOffer'])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, output_key=\"Reasoning\")\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    " \n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "Verdict: {{Verdict}}\n",
    "jobOffer: {{jobOffer}}\n",
    "personalData: {{personalData}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\" \n",
    "  \n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")  \n",
    "        \n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"Verdict\", \"jobOffer\", \"personalData\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "routerChainDesc = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chainDescription = MultiPromptChain(router_chain=routerChainDesc, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chainRank, chainDescription],\n",
    "    input_variables=[\"jobOffer\", \"personalData\"],\n",
    "    output_variables=[\"Verdict\", \"text\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain.chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "\n",
    "langchain.debug = True\n",
    "result = overall_chain({\"jobOffer\": jobOffer, \"personalData\": personalData})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2dd4c0f83caf739e5f412ceff66ea8e46f3e37bbfb794296d7dabdd86d63d0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
